import streamlit as st
import requests
import random
import time

st.set_page_config(page_title="Mi Asistente IA", page_icon="ğŸ¤–")
st.title("ğŸ¤– Mi Asistente Personal")
st.write("Â¡Hola! Estoy aquÃ­ para ayudarte con lo que necesites")

# ConfiguraciÃ³n mejorada
headers = {"Authorization": f"Bearer {st.secrets['HUGGINGFACE_TOKEN']}"}

MODELOS = [
    "https://api-inference.huggingface.co/models/microsoft/DialoGPT-large",
    "https://api-inquiry.huggingface.co/models/microsoft/DialoGPT-medium",
    "https://api-inquiry.huggingface.co/models/facebook/blenderbot-400M-distill"
]

def obtener_respuesta_inteligente(mensaje):
    """VersiÃ³n mejorada con respuestas mÃ¡s contextuales"""
    
    # Primero intentar con Hugging Face
    for modelo_url in MODELOS:
        try:
            response = requests.post(
                modelo_url,
                headers=headers,
                json={"inputs": mensaje, "parameters": {"max_length": 150}},
                timeout=10
            )
            
            if response.status_code == 200:
                resultado = response.json()
                if resultado and isinstance(resultado, list) and len(resultado) > 0:
                    texto = resultado[0].get('generated_text', '')
                    if texto and len(texto) > 15:
                        return texto
            time.sleep(1)
        except:
            continue
    
    # RESPUESTAS MEJORADAS Y CONTEXTUALES
    mensaje_lower = mensaje.lower()
    
    # Detectar tipo de pregunta
    if any(palabra in mensaje_lower for palabra in ['hola', 'hi', 'hello', 'buenas']):
        return "Â¡Hola! ğŸ‘‹ Soy tu asistente de IA. Â¿En quÃ© puedo ayudarte hoy?"
    
    elif any(palabra in mensaje_lower for palabra in ['cÃ³digo', 'code', 'program', 'python', 'script']):
        return "Â¡Claro! Puedo ayudarte con cÃ³digo Python. Â¿QuÃ© tipo de script necesitas? Por ejemplo: 'quiero un script para descargar videos' o 'necesito un bot de Telegram'"
    
    elif any(palabra in mensaje_lower for palabra in ['cÃ³mo', 'how', 'funciona', 'ayuda']):
        return "Puedo ayudarte con: programaciÃ³n, ideas de proyectos, explicaciones tÃ©cnicas, y mucho mÃ¡s. Â¿QuÃ© necesitas especÃ­ficamente?"
    
    elif '?' in mensaje:
        return "Buena pregunta. Los servicios de IA estÃ¡n ocupados en este momento, pero puedo intentar ayudarte si reformulas tu pregunta o me das mÃ¡s detalles."
    
    else:
        respuestas_contextuales = [
            f"Entiendo que quieres hablar sobre '{mensaje}'. Los servidores de IA estÃ¡n temporariamente ocupados, pero estoy aquÃ­ para ayudarte. Â¿Puedes darme mÃ¡s detalles?",
            f"Interesante pregunta sobre {mensaje}. Los modelos estÃ¡n procesando muchas solicitudes. Â¿Te importarÃ­a reformularla o intentar en unos minutos?",
            f"Â¡Me gusta tu mensaje! Los servicios gratuitos estÃ¡n saturados ahora mismo. Mientras se liberan, Â¿hay algo especÃ­fico en lo que pueda asistirte?",
            f"RecibÃ­ tu mensaje. Los sistemas de IA estÃ¡n al mÃ¡ximo de capacidad. Â¿Puedes intentar de nuevo en un momento o ser mÃ¡s especÃ­fico en tu consulta?"
        ]
        return random.choice(respuestas_contextuales)

# Interfaz de chat mejorada
if "historial" not in st.session_state:
    st.session_state.historial = []

# Mostrar historial
for mensaje in st.session_state.historial:
    with st.chat_message(mensaje["role"]):
        st.markdown(mensaje["content"])

# Input del usuario
if pregunta := st.chat_input("Escribe tu pregunta aquÃ­..."):
    # Agregar pregunta del usuario
    st.session_state.historial.append({"role": "user", "content": pregunta})
    with st.chat_message("user"):
        st.markdown(pregunta)
    
    # Obtener respuesta mejorada
    with st.chat_message("assistant"):
        with st.spinner("Analizando tu pregunta..."):
            respuesta = obtener_respuesta_inteligente(pregunta)
        
        st.markdown(respuesta)
        st.session_state.historial.append({"role": "assistant", "content": respuesta})
